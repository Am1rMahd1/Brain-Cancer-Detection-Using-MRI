{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sh_AJe4n3FFP",
    "outputId": "83a8e80f-af29-4502-b40b-0d159e8e1e15"
   },
   "source": [
    "!pip install -q ultralytics torch torchvision roboflow"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FnfwTl0N3RKG",
    "outputId": "9ed6f1d0-777f-41ff-9835-01dd48b228cf"
   },
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vd1glcRO3VFF",
    "outputId": "4786b5ed-02f1-4750-d6e7-3ce63d4323fa"
   },
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4onSVsFz3YGa",
    "outputId": "ab1f39c9-4432-43f5-eb55-0fdc2ad195fa"
   },
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"fXOGAkIOaCBMMrx0pgxg\")\n",
    "project = rf.workspace(\"my-personal-workspace-d84lu\").project(\"yolo-fj4s3-gm7mf\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RGHklNo_3kxn"
   },
   "source": [
    "params = {\n",
    "    \"imgsz\": 512,\n",
    "    \"epochs\": 50,\n",
    "    \"batch\": 16,\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"patience\": 50,\n",
    "    \"workers\": 8,\n",
    "    \"max_det\": 300,\n",
    "    \"momentum\": 0.937,\n",
    "    \"iou\": 0.7\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L7ZverA24awN"
   },
   "source": [
    "# مسیر فایل yaml دیتاست\n",
    "dataset_yaml = \"YOLO-1/data.yaml\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-tzupXa3qSU",
    "outputId": "d0514b88-10d2-4019-8fe6-e520f09d978a"
   },
   "source": [
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "results = model.train(\n",
    "    data=dataset_yaml,\n",
    "    imgsz=params[\"imgsz\"],\n",
    "    epochs=params[\"epochs\"],\n",
    "    batch=params[\"batch\"],\n",
    "    optimizer=params[\"optimizer\"],\n",
    "    patience=params[\"patience\"],\n",
    "    workers=params[\"workers\"],\n",
    "    max_det=params[\"max_det\"],\n",
    "    momentum=params[\"momentum\"],\n",
    "    iou=params[\"iou\"],\n",
    "    device=0  # اگر GPU داری، در غیر این صورت device=\"cpu\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "8xcBBY5j333K",
    "outputId": "0a39e38b-8c50-43e9-da73-1e688deb9221"
   },
   "source": [
    "results.plot()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fd0e5a29",
    "outputId": "d95ab893-5c9f-42b8-8ae4-36da57433fce"
   },
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Display the training plot\n",
    "display(Image(filename='runs/detect/train/results.png'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQVPe4t_6oso",
    "outputId": "12ad5f28-3bd3-414b-b2c8-587cd426068f"
   },
   "source": [
    "metrics = model.val(data=dataset_yaml, imgsz=params[\"imgsz\"], batch=params[\"batch\"])\n",
    "print(metrics)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gsEAV2le6peo"
   },
   "source": [
    "from ultralytics.utils.plotting import plot_results\n",
    "plot_results('runs/detect/train/results.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OPB6f5DE7ZOA"
   },
   "source": [
    "metrics.confusion_matrix.plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lI48nb5P7vG1",
    "outputId": "1104838f-8613-468a-e839-91fde8afec7f"
   },
   "source": [
    "results = model.predict('YOLO-1/test/images/y76_jpg.rf.9157d1b89ba0ac6b94cbc078bd180f5d.jpg', save=True, conf=0.25)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Another Faster R-CNN Exp"
   ],
   "metadata": {
    "id": "njSBNE773mt_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# (This is an example, your code might be slightly different)\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "\n",
    "# Get the number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# Replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=2) # num_classes = background + tumor\n"
   ],
   "metadata": {
    "id": "YZdVzogd7h2b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "import time\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "LR_STEP_SIZE = 10\n",
    "LR_GAMMA = 0.1\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# --- Ensure model is on the correct device ---\n",
    "# We assume 'model' is now a freshly initialized model in your environment\n",
    "# after you re-ran your model definition cell.\n",
    "model.to(device)\n",
    "\n",
    "# --- Setup Optimizer and Scheduler ---\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEP_SIZE, gamma=LR_GAMMA)\n",
    "\n",
    "# Variables to track the best model\n",
    "best_map = -1.0\n",
    "best_model_weights = None\n",
    "\n",
    "print(\"--- Starting Experiment 2 (Corrected): 30 Epochs with LR Scheduler ---\")\n",
    "\n",
    "# --- Main Training and Evaluation Loop ---\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # --- Training Phase ---\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for i, (images, targets) in enumerate(train_data_loader):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += losses.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_data_loader)\n",
    "\n",
    "    # Update the learning rate\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    metric = MeanAveragePrecision(box_format='xyxy')\n",
    "    with torch.no_grad():\n",
    "        for images, targets in valid_data_loader:\n",
    "            images = list(img.to(device) for img in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            predictions = model(images)\n",
    "            metric.update(predictions, targets)\n",
    "\n",
    "    results = metric.compute()\n",
    "    current_map = results['map'].item()\n",
    "\n",
    "    # --- Epoch Summary ---\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
    "        f\"Time: {epoch_time:.1f}s | \"\n",
    "        f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "        f\"Validation mAP: {current_map:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Check if this is the best model so far\n",
    "    if current_map > best_map:\n",
    "        best_map = current_map\n",
    "        best_model_weights = model.state_dict()\n",
    "        print(f\"*** New best model found! mAP: {best_map:.4f} at epoch {epoch+1} ***\")\n",
    "\n",
    "print(\"--- Finished Training ---\")\n",
    "print(f\"Best Validation mAP achieved: {best_map:.4f}\")\n",
    "\n",
    "# Load the best performing model weights for future use\n",
    "if best_model_weights:\n",
    "    model.load_state_dict(best_model_weights)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hM5zVrxF2I5i",
    "outputId": "1453bc7d-2c09-4627-c889-24dbb977e958"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# --- Visualization Function (Corrected) ---\n",
    "def visualize_predictions(model, data_loader, device, num_images=5):\n",
    "    \"\"\"\n",
    "    Picks random images from a data loader, runs them through the model,\n",
    "    and displays the ground truth and predicted bounding boxes.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Get a batch of images and targets\n",
    "    images, targets = next(iter(data_loader))\n",
    "\n",
    "    # Pick random images from the batch\n",
    "    indices = random.sample(range(len(images)), k=min(num_images, len(images)))\n",
    "\n",
    "    # Move images and model to the correct device\n",
    "    images_for_model = [images[i].to(device) for i in indices]\n",
    "    model.to(device)\n",
    "\n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images_for_model)\n",
    "\n",
    "    # --- Plotting ---\n",
    "    for i, (pred_dict, original_idx) in enumerate(zip(predictions, indices)):\n",
    "        # Use the original, un-moved image for plotting\n",
    "        image_tensor = images[original_idx]\n",
    "        image_display = image_tensor.permute(1, 2, 0) # CHW -> HWC\n",
    "\n",
    "        fig, ax = plt.subplots(1, figsize=(10, 8))\n",
    "        ax.imshow(image_display)\n",
    "\n",
    "        # --- Draw Ground Truth Boxes (in Green) ---\n",
    "        true_boxes = targets[original_idx]['boxes']\n",
    "        for box in true_boxes:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                 linewidth=2, edgecolor='g', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(xmin, ymin, 'Ground Truth', color='g', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "        # --- Draw Predicted Boxes (in Red) ---\n",
    "        # *** THE FIX IS HERE: Move predictions to CPU ***\n",
    "        pred_boxes = pred_dict['boxes'].cpu()\n",
    "        pred_scores = pred_dict['scores'].cpu()\n",
    "\n",
    "        # Filter out low-confidence predictions\n",
    "        for box, score in zip(pred_boxes, pred_scores):\n",
    "            if score > 0.5: # Confidence threshold\n",
    "                xmin, ymin, xmax, ymax = box\n",
    "                rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                     linewidth=2, edgecolor='r', facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                ax.text(xmin, ymin, f'Pred: {score:.2f}', color='r', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "        ax.set_title(f\"Image {i+1}: Ground Truth (Green) vs. Prediction (Red)\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# --- Run the visualization ---\n",
    "print(\"--- Visualizing Model Predictions on Validation Set (Corrected) ---\")\n",
    "visualize_predictions(model, valid_data_loader, device, num_images=30)\n"
   ],
   "metadata": {
    "id": "XkMC1iuS3we1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "ac5da879-6e15-48fd-b710-6849373cd9e0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "YiP_mN7HQaFf"
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
